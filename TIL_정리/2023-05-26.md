# 2023-05-26 TIL

### 키워드
- HashMap의 Load Factor
- Rehashing란
- Rehashing을 하는 이유
- Rehashing 과정

## HashMap 의 Load Factor
### Capacity
- HashMap의 버킷수
- initial capacity : Map 이 생성될 때의 capacity
- HashMap에 요소들이 추가될 때 마다 capacity가 늘어간다
- HashMap의 default inital capacity는 `16` 이다
- Map을 생성할 때, capacity를 줄 수 있다
```java
Map<String, String> mapWithInitialCapacity = new HashMap<>(5);
```

### Load Factor
- Map에 버킷이 얼마나 가득 차 있는지를 나타내는 숫자, 이 값을 통해 Map의 capacity를 언제 늘릴지 결정한다
- HashMap은 항상 고정된 구조를 가지고 있는 것이 아닌, `capacity(hashMap 에서의 버킷수)` 와 `load factor` 라는 변수를 가지고 동적으로 변화한다  
- load factor 값이 적게 유지되어야 hash의 시간복잡도를 `O(1)` 로 유지할 수가 있다
- HashMap의 default load factor는 capacity의 `75%` 이다 
- Map을 생성할 때 capacity와 함께, load factor도 지정할 수 있다
```java
Map<String, String> mapWithInitialCapacityAndLF = new HashMap<>(5, 0.5f);
```

## HashMap의 성능
- `hashcode()` 가 잘 작성되어있으면, HashMap은 모든 bucket에 걸쳐 요소들이 잘 분포되어 있는 형태로 저장을 할 것 => `O(1)`
- 위의 경우가 아니라 bucket 사이즈는 고정되어 있는데, 저장하는 요소들이 증가한다고 해보자, 이런 경우 성능이 안좋아질 수 밖에 없다
- 그래서 이렇게 요소 개수가 늘어날 때는 bucket 의 개수를 늘리는데, bucket의 개수를 늘리면서 bucket에 각 요소들이 잘 분포되어 있을 수 있게 저장된 요소들을 재분배한다
- 이러한 방법을 통해서 시간복잡도를 `O(1)` 로 유지하게 된다
- 결국, 위에서 알아본 load factor가 언제 bucket의 수를 늘려야하는지 결정해주는 역할을 한다
  - load factor가 너무 적은 값이면, 빈 채로 남아있는 bucket이 많아 비효율적이지만 충돌은 덜 발생할 수 있다
  - load factor가 너무 큰 값이라면, 공간 복잡도가 `O(n)` 인 HashMap의 공간 오버헤드를 줄일 수는 있겠지만 탐색에 소요되는 시간이 늘어나게 된다 (탐색의 성능이 저하된다)

## Rehashing
- 이미 저장되어 있는 요소들의 hashcode를 새롭게 계산하며 HashMap 사이즈를 늘리고, 새로운 해시 값에 기반하여 새로운 bucket으로 요소들을 옮기는 과정

### 왜 rehashing을 진행하는가?
- 높은 수의 load factor로 인해 발생하는 해시 충돌을 막고, hashmap의 효율적인 탐색을 유지하며 탐색 성능을 향상시키려고 rehashing을 진행한다
- Java 의 HashMap은 rehashing 시 Map의 capacity를 2배로 늘린다
- Rehashing 과정 또한 시간 및 공간이 많이 필요한 작업이지만, hashmap의 효율적인 탐색을 유지하기 위해서 필요한 사항이다

## Rehashing의 과정
- Map에 새로운 요소가 추가될 때마다, load factor를 검사한다
- 지정된 load factor (ex) default는 0.75) 보다 현재 load factor가 커지면 Rehashing을 진행한다
- Rehashing 과정에서는, 이전의 bucket 사이즈보다 2배로 bucket 사이즈를 늘린다
- 기존 bucket을 순회하면서 저장된 각 요소를 재해싱하여(해시코드를 다시 계산하여) 새로운 bucket에 추가한다 
